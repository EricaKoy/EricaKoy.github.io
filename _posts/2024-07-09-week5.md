---
layout: post
title: Week 5 (Jul 3 - Jul 9)
---

This week, I visualed the NeuroSEED data that were replicated last week as boxplots. First, I made several updates to the avg_score function, including returning each score individually instead of computing the average. To determine how different seeds impact the accuracy score, I modified the code to pick a provided number of random seeds, which was used to create a random sample from the database. After these changes, I created a boxplot for the control, scikit-learn, and hyperDT models using the NeuroSEED data. The data we obtained was expected, where hyperDT performed better than both models. This assumption is based on the understanding that NeuroSEED has a tree-like structure, which naturally aligns with hyperbolic geometry. Hyperbolic spaces are known for their ability to efficiently represent hierarchical and tree-like data structures, making them a better model to model NeuroSEED data over scikit-learn which is Euclidean. 

At the end of the week, I met with Philippe to discuss the process of converting datasets to be hyperbolic. He explained two methods: coordinate optimization and mixed-curvature VAE (Variational Autoencoder). For coordinate optimization, the input is a set of pairwise distances, and the parameters are embeddings. The process directly optimizes the embeddings based on their pairwise distances, and he refered me to code that he had already written. The mixed-curvature VAE method involves inputting a set of points and optimizing an encoder-decoder pair. Philippe recommended becoming familiar with VAE and suggested resources like "Towards Data Science" for further understanding.