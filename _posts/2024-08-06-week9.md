---
layout: post
title: Week 9 (Jul 31 - Aug 6)
---


1. Play around with the params, get d_avg and hyperDT and DT scores
•	Different signatures (-2 to 2, you can get denser range of d_avg)
•	Seeds 
•	Hyperparams 
Run algorithm for longer (more iterations)
Philippe saw that loss function converges before structure emerges, so loss function looks like it is doing good but actually the structure is terrible
2. How much can we bring down D_avg
Assuming signature = (-1, 6), any param change to bring down d_avg?
3. Scatterplots for single manifold: 
•	D_avg vs hyperDT minus DT (the higher the better hyperDT does)
o	Would be interesting if saw inverse correlation
•	Curvature vs D_avg
o	Can find optimal curvature where D_avg hits the minimum
•	Curvature vs difference
Can color by curvature 
4. Embed americangut using same embedders 
Notes: expoenential mapping for learning rate 
multidimensional scaling: uses eigen decomposition of covariance matrix to find distance 
    variant of pca 
    cant do on manifold so have to do something else 
initialize by doing multidim scaling, project onto hyperbolic space, prob do multidim sclaing onto 6 dim, then exp map on origin 